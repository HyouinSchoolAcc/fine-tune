{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Pseudocode\n",
    "## Function: Handle User Request\n",
    "```python\n",
    "def handle_user_request(user, query, target_waifu):\n",
    "    # Step 1: Retrieve relevant data\n",
    "    waifu_data = database[user][target_waifu]\n",
    "    past_convo = waifu_data[\"past_conversations\"]\n",
    "    event_status = waifu_data[\"current_event_status\"]\n",
    "    last_contact_time = waifu_data[\"last_contact_time\"]\n",
    "    waifu_data[\"last_contact_time\"] = time.now()\n",
    "\n",
    "    # Step 2: Update event_status if the last contact exceeds the threshold\n",
    "    if time.now() - last_contact_time > threshold_of_update:\n",
    "        event_status = GPT_update(event_status, target_waifu, last_contact_time)\n",
    "\n",
    "    # Step 3: Prepare the prompt for the LLM\n",
    "    prompt = (\n",
    "        f\"You are {target_waifu}, you talked about {past_convo}, \"\n",
    "        f\"your recent thoughts and events are {event_status}, \"\n",
    "        f\"and here's the new input: {query}. Respond appropriately. \"\n",
    "        f\"Additionally, after your response add a '$$' sign. \"\n",
    "        f\"If you decide the event has changed, type the new events after the '$$' sign.\"\n",
    "    )\n",
    "\n",
    "    # Step 4: Generate response using LLM\n",
    "    response = LLM(prompt)  # The LLM updates event_status implicitly if necessary\n",
    "\n",
    "    # Step 5: Log the request and response\n",
    "    waifu_data[\"past_conversations\"].append({\"query\": query, \"response\": response})\n",
    "\n",
    "    # Step 6: Save updated event_status to the database\n",
    "    waifu_data[\"current_event_status\"] = event_status\n",
    "    database.save()\n",
    "\n",
    "    return response\n",
    "\n",
    "## Function: Handle Trigger Event\n",
    "def handle_trigger_event(user, query, target_waifu, event_number):\n",
    "    # Step 1: Retrieve relevant data\n",
    "    waifu_data = database[user][target_waifu]\n",
    "    past_convo = waifu_data[\"past_conversations\"]\n",
    "    event_status = waifu_data[\"current_event_status\"]\n",
    "    last_contact_time = waifu_data[\"last_contact_time\"]\n",
    "\n",
    "    # Step 2: Update event_status with the completed event\n",
    "    event_status = GPT_update_completed_event(event_status, target_waifu, last_contact_time, event_number)\n",
    "\n",
    "    # Step 3: Prepare the prompt for the LLM\n",
    "    prompt = (\n",
    "        f\"Event {event_number} has been completed. Here is the updated context: {event_status}. \"\n",
    "        f\"Additionally, {past_convo} was discussed earlier. New input: {query}. \"\n",
    "        f\"Provide a response and, if applicable, update event details after the '$$' sign.\"\n",
    "    )\n",
    "\n",
    "    # Step 4: Generate response using LLM\n",
    "    response = LLM(prompt)\n",
    "\n",
    "    # Step 5: Log the trigger event\n",
    "    waifu_data[\"event_status_log\"].append({\n",
    "        \"user\": user,\n",
    "        \"query\": query,\n",
    "        \"target_waifu\": target_waifu,\n",
    "        \"event_number\": event_number\n",
    "    })\n",
    "\n",
    "    # Step 6: Save updated event_status to the database\n",
    "    waifu_data[\"current_event_status\"] = event_status\n",
    "    database.save()\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "## For either case\n",
    "```python\n",
    "    response = handle_trigger_event(user, query, target_waifu, event_number)\n",
    "    response = handle_user_request(user, query, target_waifu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
