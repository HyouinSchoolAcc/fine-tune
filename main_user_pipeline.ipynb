{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Pseudocode\n",
    "\n",
    "## Function: Handle User Request (Request Type 1)\n",
    "```python\n",
    "def handle_user_request(user, payload, target_waifu):\n",
    "    # Step 1: Retrieve relevant data\n",
    "    past_convo = database[user][target_waifu][\"past_conversations\"]\n",
    "    event_status = database[user][target_waifu][\"current_event_status\"]\n",
    "    last_contact_time = database[user][target_waifu][\"last_contact_time\"]\n",
    "    \n",
    "    # Step 2: Update event_status if last contact exceeds the threshold\n",
    "    if last_contact_time > threshold_of_update:\n",
    "        event_status = GPT_update(event_status, target_waifu, last_contact_time)\n",
    "    \n",
    "    # Step 3: Prepare the prompt for the LLM\n",
    "    prompt = prompt_organizer(event_status, database[target_waifu][\"description\"], payload)\n",
    "    \n",
    "    # Step 4: Generate response using LLM, including updates to event_status if needed\n",
    "    response = LLM(prompt)  # Ensure LLM updates event_status invisibly if necessary\n",
    "    \n",
    "    # Step 5: Log trigger event if applicable\n",
    "    trigger_event = {\"user\": user, \"payload\": payload, \"target_waifu\": target_waifu}\n",
    "    database[user][target_waifu][\"event_status_log\"].append(trigger_event)\n",
    "    \n",
    "    # Step 6: Save updated event_status to the database\n",
    "    database[user][target_waifu][\"current_event_status\"] = event_status\n",
    "    database.save()\n",
    "    \n",
    "    return response\n",
    "def handle_trigger_event(user, payload, target_waifu, event_number):\n",
    "    # Step 1: Retrieve relevant data\n",
    "    past_convo = database[user][target_waifu][\"past_conversations\"]\n",
    "    event_status = database[user][target_waifu][\"current_event_status\"]\n",
    "    last_contact_time = database[user][target_waifu][\"last_contact_time\"]\n",
    "    \n",
    "    # Step 2: Update event_status with a completed event\n",
    "    event_status = GPT_update_completed_event(event_status, target_waifu, last_contact_time, event_number)\n",
    "    \n",
    "    # Step 3: Prepare the prompt for the LLM\n",
    "    prompt = prompt_organizer(event_status, database[target_waifu][\"description\"], payload)\n",
    "    \n",
    "    # Step 4: Generate response using LLM, including updates to event_status if needed\n",
    "    response = LLM(prompt)  # Ensure LLM updates event_status invisibly if necessary\n",
    "    \n",
    "    # Step 5: Log trigger event\n",
    "    trigger_event = {\n",
    "        \"user\": user, \n",
    "        \"payload\": payload, \n",
    "        \"target_waifu\": target_waifu, \n",
    "        \"event_number\": event_number\n",
    "    }\n",
    "    database[user][target_waifu][\"event_status_log\"].append(trigger_event)\n",
    "    \n",
    "    # Step 6: Save updated event_status to the database\n",
    "    database[user][target_waifu][\"current_event_status\"] = event_status\n",
    "    database.save()\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "## For either case\n",
    "```python\n",
    "    response = handle_trigger_event(user, payload, target_waifu, event_number)\n",
    "    response = handle_user_request(user, payload, target_waifu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
